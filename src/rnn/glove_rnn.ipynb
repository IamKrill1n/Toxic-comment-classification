{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"9d2dbdb3-6c74-4f96-9865-2951dfd653ce","_uuid":"bb41ad86b25fecf332927b0c8f55dd710101e33f"},"source":["# Improved Glove Rnn"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import tensorflow as tf; \n","print(tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"2f9b7a76-8625-443d-811f-8f49781aef81","_uuid":"598f965bc881cfe6605d92903b758778d400fa8b","execution":{"iopub.execute_input":"2024-05-03T04:31:45.669492Z","iopub.status.busy":"2024-05-03T04:31:45.669062Z","iopub.status.idle":"2024-05-03T04:31:48.325236Z","shell.execute_reply":"2024-05-03T04:31:48.324361Z","shell.execute_reply.started":"2024-05-03T04:31:45.669388Z"},"trusted":true},"outputs":[],"source":["import sys, os, re, csv, codecs, numpy as np, pandas as pd\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Bidirectional, GlobalMaxPool1D, SimpleRNN, GRU\n","from keras.models import Model\n","# from keras import initializers, regularizers, constraints, optimizers, layers"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["d:\\python\\Toxic-comment-classification\n"]}],"source":["%cd ../../"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["embed_size = 300 # how big is each word vector\n","max_features = 20000 # how many unique words to use (i.e num rows in embedding vector)\n","maxlen = 100 # max number of words in a comment to use\n","embed_size_str = str(embed_size)"]},{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"66a6b5fd-93f0-4f95-ad62-3253815059ba","_uuid":"729b0f0c2a02c678631b8c072d62ff46146a82ef","execution":{"iopub.execute_input":"2024-05-03T04:32:11.984567Z","iopub.status.busy":"2024-05-03T04:32:11.984220Z","iopub.status.idle":"2024-05-03T04:32:11.990085Z","shell.execute_reply":"2024-05-03T04:32:11.989005Z","shell.execute_reply.started":"2024-05-03T04:32:11.984515Z"},"trusted":true},"outputs":[],"source":["path = 'kaggle/input/'\n","submission_path = 'kaggle/working/rnn_submission/'\n","comp = 'jigsaw-toxic-comment-classification-challenge/'\n","clean_data_path = 'clean_data/'\n","EMBEDDING_FILE=f'{path}glove_embeddings/glove.6B.' + embed_size_str + 'd.txt'\n","TRAIN_DATA_FILE=f'{path}{comp}train.csv.zip'\n","TEST_DATA_FILE=f'{path}{comp}test.csv.zip'\n","CLEAN_TRAIN_DATA_FILE=f'{clean_data_path}data_train_cleaned_vanilla2.txt'\n","CLEAN_TEST_DATA_FILE=f'{clean_data_path}data_test_cleaned_vanilla2.txt'\n","SAMPLE_SUBMISSION=f'{path}{comp}sample_submission.csv.zip'\n","checkpoint_path = 'model_checkpoint/rnn'"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b3a8d783-95c2-4819-9897-1320e3295183","_uuid":"4dd8a02e7ef983f10ec9315721c6dda2958024af"},"source":["#### Read data"]},{"cell_type":"code","execution_count":6,"metadata":{"_cell_guid":"ac2e165b-1f6e-4e69-8acf-5ad7674fafc3","_uuid":"8ab6dad952c65e9afcf16e43c4043179ef288780","execution":{"iopub.execute_input":"2024-05-03T04:32:15.437940Z","iopub.status.busy":"2024-05-03T04:32:15.437635Z","iopub.status.idle":"2024-05-03T04:32:19.056635Z","shell.execute_reply":"2024-05-03T04:32:19.055861Z","shell.execute_reply.started":"2024-05-03T04:32:15.437896Z"},"trusted":true},"outputs":[],"source":["train = pd.read_csv(TRAIN_DATA_FILE)\n","test = pd.read_csv(TEST_DATA_FILE)\n","\n","def read_from_file(filename):\n","    with open(filename, 'r') as f:\n","        return f.read().splitlines()    \n","    \n","list_sentences_train = read_from_file(CLEAN_TRAIN_DATA_FILE)\n","list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n","y = train[list_classes].values\n","list_sentences_test = read_from_file(CLEAN_TEST_DATA_FILE)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"54a7a34e-6549-45f7-ada2-2173ff2ce5ea","_uuid":"e8810c303980f41dbe0543e1c15d35acbdd8428f"},"source":["Standard keras preprocessing, to turn each comment into a list of word indexes of equal length (with truncation or padding as needed)."]},{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"79afc0e9-b5f0-42a2-9257-a72458e91dbb","_uuid":"c292c2830522bfe59d281ecac19f3a9415c07155","execution":{"iopub.status.busy":"2024-05-03T04:31:48.589262Z","iopub.status.idle":"2024-05-03T04:31:48.589761Z"},"trusted":true},"outputs":[],"source":["tokenizer = Tokenizer(num_words=max_features)\n","tokenizer.fit_on_texts(list(list_sentences_train))\n","list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n","list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n","X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n","X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# import json, io\n","\n","# tokenizer_json = tokenizer.to_json()\n","# with io.open(checkpoint_path + 'tokenizer.json', 'w', encoding='utf-8') as f:\n","#     f.write(json.dumps(tokenizer_json, ensure_ascii=False))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f8c4f6a3-3a19-40b1-ad31-6df2690bec8a","_uuid":"e1cb77629e35c2b5b28288b4d6048a86dda04d78"},"source":["Read the glove word vectors (space delimited strings) into a dictionary from word->vector."]},{"cell_type":"code","execution_count":8,"metadata":{"_cell_guid":"7d19392b-7750-4a1b-ac30-ed75b8a62d52","_uuid":"e9e3b4fa7c4658e0f22dd48cb1a289d9deb745fc","execution":{"iopub.status.busy":"2024-05-03T04:31:48.590705Z","iopub.status.idle":"2024-05-03T04:31:48.591016Z"},"trusted":true},"outputs":[],"source":["def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n","embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE))"]},{"cell_type":"markdown","metadata":{"_cell_guid":"7370416a-094a-4dc7-84fa-bdbf469f6579","_uuid":"20cea54904ac1eece20874e9346905a59a604985"},"source":["Use these vectors to create our embedding matrix, with random initialization for words that aren't in GloVe. We'll use the same mean and stdev of embeddings the GloVe has when generating the random init."]},{"cell_type":"code","execution_count":9,"metadata":{"_cell_guid":"4d29d827-377d-4d2f-8582-4a92f9569719","_uuid":"96fc33012e7f07a2169a150c61574858d49a561b","execution":{"iopub.status.busy":"2024-05-03T04:31:48.591818Z","iopub.status.idle":"2024-05-03T04:31:48.592292Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(-0.0039050116, 0.38177028)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["all_embs = np.stack(list(embeddings_index.values()))\n","emb_mean,emb_std = all_embs.mean(), all_embs.std()\n","emb_mean,emb_std"]},{"cell_type":"code","execution_count":10,"metadata":{"_cell_guid":"62acac54-0495-4a26-ab63-2520d05b3e19","_uuid":"574c91e270add444a7bc8175440274bdd83b7173","execution":{"iopub.status.busy":"2024-05-03T04:31:48.593347Z","iopub.status.idle":"2024-05-03T04:31:48.593987Z"},"trusted":true},"outputs":[],"source":["word_index = tokenizer.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"]},{"cell_type":"markdown","metadata":{"_cell_guid":"f1aeec65-356e-4430-b99d-bb516ec90b09","_uuid":"237345510bd2e664b5c6983a698d80bac2732bc4"},"source":["#### Create Model"]},{"cell_type":"code","execution_count":11,"metadata":{"_cell_guid":"0d4cb718-7f9a-4eab-acda-8f55b4712439","_uuid":"dc51af0bd046e1eccc29111a8e2d77bdf7c60d28","execution":{"iopub.status.busy":"2024-05-03T04:31:48.594948Z","iopub.status.idle":"2024-05-03T04:31:48.595626Z"},"trusted":true},"outputs":[],"source":["from keras.metrics import AUC\n","\n","def get_model(layertype='RNN', use_dropout=False, dropout_rate=0.1):\n","    inp = Input(shape=(maxlen, ))\n","    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n","    if layertype == 'RNN' and not use_dropout:\n","        x = Bidirectional(SimpleRNN(60, return_sequences=True))(x)\n","    elif layertype == 'LSTM' and not use_dropout:\n","        x = Bidirectional(LSTM(60, return_sequences=True))(x)\n","    elif layertype == 'GRU' and not use_dropout:\n","        x = Bidirectional(GRU(60, return_sequences=True))(x)\n","    elif layertype == 'RNN' and use_dropout:\n","        x = Bidirectional(SimpleRNN(60, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))(x)\n","    elif layertype == 'LSTM' and use_dropout:\n","        x = Bidirectional(LSTM(60, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))(x)\n","    elif layertype == 'GRU' and use_dropout:\n","        x = Bidirectional(GRU(60, return_sequences=True, dropout=dropout_rate, recurrent_dropout=dropout_rate))(x)\n","    x = GlobalMaxPool1D()(x)\n","    x = Dropout(dropout_rate)(x)\n","    x = Dense(60, activation=\"relu\")(x)\n","    x = Dropout(dropout_rate)(x)\n","    x = Dense(6, activation=\"sigmoid\")(x)\n","    model = Model(inputs=inp, outputs=x)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer='adam',\n","                  metrics=[AUC(name='auc')])\n","    return model"]},{"cell_type":"markdown","metadata":{"_cell_guid":"4a624b55-3720-42bc-ad5a-7cefc76d83f6","_uuid":"e2a0e9ce12e1ff5ea102665e79de23df5caf5802"},"source":["#### Create Validation Set"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# from sklearn.model_selection import train_test_split\n","# X_train, X_val, y_train, y_val = train_test_split(X_t, y, test_size=0.1, random_state=7)"]},{"cell_type":"markdown","metadata":{},"source":["#### Modelcheckpoint\n","\n","Use val_auc to monitor when not submitting"]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"333626f1-a838-4fea-af99-0c78f1ef5f5c","_uuid":"c1558c6b2802fc632edc4510c074555a590efbd8","execution":{"iopub.status.busy":"2024-05-03T04:31:48.596575Z","iopub.status.idle":"2024-05-03T04:31:48.597069Z"},"trusted":true},"outputs":[],"source":["from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n","\n","# class CustomCallback(Callback):\n","#     def on_train_begin(self, logs={}):\n","#         self.losses = []\n","#         self.aucs = []\n","\n","#     def on_batch_end(self, batch, logs={}):\n","#         if batch % 500 == 0:\n","#             loss, auc = self.model.evaluate(X_val, y_val, verbose=0)\n","#             self.losses.append(loss)\n","#             self.aucs.append(auc)\n","#             print(f'\\nEvaluation at batch {batch}: Loss = {loss}, AUC = {auc}\\n')\n","\n","# # Instantiate the custom callback\n","# custom_callback = CustomCallback()\n","rnn_checkpoint = ModelCheckpoint(checkpoint_path + 'glove' + embed_size_str + '_rnn.keras', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n","lstm_checkpoint = ModelCheckpoint(checkpoint_path + 'glove' + embed_size_str + '_lstm.keras', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n","gru_checkpoint = ModelCheckpoint(checkpoint_path + 'glove' + embed_size_str + '_gru.keras', monitor='val_auc', mode='max', save_best_only=True, verbose=1)\n","# early_stopping = EarlyStopping(monitor='loss', min_delta=0.0005, restore_best_weights=True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","\n","# def plot_loss(callback):\n","#     plt.figure(figsize=(12,6))\n","#     plt.plot(callback.losses)\n","#     plt.title('model loss')\n","#     plt.ylabel('loss')\n","#     plt.xlabel('500 batch')\n","#     plt.legend(['train', 'test'], loc='upper left')\n","#     plt.show()\n","    \n","# def plot_auc(callback):\n","#     plt.figure(figsize=(12,6))\n","#     plt.plot(callback.aucs)\n","#     plt.title('model AUC')\n","#     plt.ylabel('AUC')\n","#     plt.xlabel('500 batch')\n","#     plt.legend(['train', 'test'], loc='upper left')\n","#     plt.show()\n","\n","# def plot_loss_auc(history):\n","#     plot_loss(history)\n","#     plot_auc(history)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," embedding_3 (Embedding)     (None, 100, 300)          6000000   \n","                                                                 \n"," bidirectional_3 (Bidirectio  (None, 100, 120)         43320     \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d_3 (Glo  (None, 120)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_6 (Dropout)         (None, 120)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 60)                7260      \n","                                                                 \n"," dropout_7 (Dropout)         (None, 60)                0         \n","                                                                 \n"," dense_7 (Dense)             (None, 6)                 366       \n","                                                                 \n","=================================================================\n","Total params: 6,050,946\n","Trainable params: 6,050,946\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = get_model('RNN', True, 0.15)\n","model.summary()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","  19/4488 [..............................] - ETA: 24:06 - loss: 0.2724 - auc: 0.5678"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      2\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mrnn_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[1;32md:\\python\\Toxic-comment-classification\\.conda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["batch_size = 32\n","epochs = 2\n","model.fit(X_t,y, batch_size=batch_size, epochs=epochs, callbacks=[rnn_checkpoint], validation_split=0.1)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"d6fa2ace-aa92-40cf-913f-a8f5d5a4b130","_uuid":"3dbaa4d0c22271b8b0dc7e58bcad89ddc607beaf"},"source":["And finally, get predictions for the test set and prepare a submission CSV:"]},{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"28ce30e3-0f21-48e5-af3c-7e5512c9fbdc","_uuid":"e59ad8a98ac5bb25a6bddd72718f3ed8a7fb52e0","execution":{"iopub.status.busy":"2024-05-03T04:31:48.598002Z","iopub.status.idle":"2024-05-03T04:31:48.598531Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 79ms/step\n"]}],"source":["model.load_weights(checkpoint_path + 'glove' + embed_size_str + '_rnn.keras')\n","sample_submission = pd.read_csv(SAMPLE_SUBMISSION)\n","y_test = model.predict([X_te], batch_size=1024, verbose=1)\n","sample_submission[list_classes] = y_test\n","sample_submission.to_csv(submission_path + 'rnn_glove' + embed_size_str + '_submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Build Lstm model"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","Model: \"model_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," embedding_4 (Embedding)     (None, 100, 300)          6000000   \n","                                                                 \n"," bidirectional_4 (Bidirectio  (None, 100, 120)         173280    \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d_4 (Glo  (None, 120)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_8 (Dropout)         (None, 120)               0         \n","                                                                 \n"," dense_8 (Dense)             (None, 60)                7260      \n","                                                                 \n"," dropout_9 (Dropout)         (None, 60)                0         \n","                                                                 \n"," dense_9 (Dense)             (None, 6)                 366       \n","                                                                 \n","=================================================================\n","Total params: 6,180,906\n","Trainable params: 6,180,906\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["del model\n","model = get_model('LSTM', True, 0.15)\n","model.summary()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","\u001b[1m4987/4987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - auc: 0.9554 - loss: 0.0681\n","Epoch 1: auc improved from -inf to 0.97706, saving model to model_checkpoint/rnnglove300_lstm.keras\n","\u001b[1m4987/4987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 47ms/step - auc: 0.9554 - loss: 0.0681\n","Epoch 2/2\n","\u001b[1m4986/4987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - auc: 0.9863 - loss: 0.0417\n","Epoch 2: auc improved from 0.97706 to 0.98661, saving model to model_checkpoint/rnnglove300_lstm.keras\n","\u001b[1m4987/4987\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 60ms/step - auc: 0.9863 - loss: 0.0417\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x1b8b89118d0>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_t,y, batch_size=batch_size, epochs=epochs, callbacks=[lstm_checkpoint])"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 320ms/step\n"]}],"source":["model.load_weights(checkpoint_path + 'glove' + embed_size_str + '_lstm.keras')\n","sample_submission = pd.read_csv(SAMPLE_SUBMISSION)\n","y_test = model.predict([X_te], batch_size=1024, verbose=1)\n","sample_submission[list_classes] = y_test\n","sample_submission.to_csv(submission_path + 'lstm_glove' + embed_size_str + '_submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["Build GRU model"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 100)]             0         \n","                                                                 \n"," embedding_1 (Embedding)     (None, 100, 300)          6000000   \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 100, 120)         130320    \n"," nal)                                                            \n","                                                                 \n"," global_max_pooling1d_1 (Glo  (None, 120)              0         \n"," balMaxPooling1D)                                                \n","                                                                 \n"," dropout_2 (Dropout)         (None, 120)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 60)                7260      \n","                                                                 \n"," dropout_3 (Dropout)         (None, 60)                0         \n","                                                                 \n"," dense_3 (Dense)             (None, 6)                 366       \n","                                                                 \n","=================================================================\n","Total params: 6,137,946\n","Trainable params: 6,137,946\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["del model\n","model = get_model('GRU', False, 0.1)\n","model.summary()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/2\n","4486/4488 [============================>.] - ETA: 0s - loss: 0.0527 - auc: 0.9776\n","Epoch 1: val_auc improved from -inf to 0.97988, saving model to model_checkpoint\\rnnglove300_gru.keras\n","4488/4488 [==============================] - 101s 22ms/step - loss: 0.0527 - auc: 0.9776 - val_loss: 0.0468 - val_auc: 0.9799\n","Epoch 2/2\n","4486/4488 [============================>.] - ETA: 0s - loss: 0.0403 - auc: 0.9875\n","Epoch 2: val_auc improved from 0.97988 to 0.98020, saving model to model_checkpoint\\rnnglove300_gru.keras\n","4488/4488 [==============================] - 96s 21ms/step - loss: 0.0403 - auc: 0.9875 - val_loss: 0.0456 - val_auc: 0.9802\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1d3a9b53fa0>"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(X_t,y, batch_size=batch_size, epochs=epochs, callbacks=[gru_checkpoint], validation_split=0.1)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 149ms/step\n"]}],"source":["model.load_weights(checkpoint_path + 'glove' + embed_size_str + '_gru.keras')\n","sample_submission = pd.read_csv(SAMPLE_SUBMISSION)\n","y_test = model.predict([X_te], batch_size=1024, verbose=1)\n","sample_submission[list_classes] = y_test\n","sample_submission.to_csv(submission_path + 'gru_glove' + embed_size_str + '_submission.csv', index=False)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":44219,"sourceId":8076,"sourceType":"competition"},{"datasetId":6080,"sourceId":8967,"sourceType":"datasetVersion"}],"dockerImageVersionId":41,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.19"}},"nbformat":4,"nbformat_minor":4}
